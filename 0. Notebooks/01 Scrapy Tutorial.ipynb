{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy Tutorial\n",
    "\n",
    "공식 문서 튜토리얼 따라하기 [doc.scrapy](https://doc.scrapy.org/en/2.0/intro/tutorial.html)\n",
    "\n",
    "유명한 인용문들을 [quotes.toscrape.com](http://quotes.toscrape.com/) 에서 스크랩해보자\n",
    "\n",
    "아래의 순서로 진행,\n",
    "\n",
    "   1. 새로운 Scrapy project 생성\n",
    "   2. 사이트를 크롤링하고 데이터를 추출하기 위한 spider 작성\n",
    "   3. command line을 사용하여 스크랩 된 데이터 내보내기\n",
    "   4. 재귀적으로 링크를 따라 들어가도록 spider 수정\n",
    "   5. spider arguments 사용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a project\n",
    "\n",
    "프로젝트를 생성할 디렉토리를 정하고 아래 명령어를 통해 새로운 프로젝트를 생성한다.\n",
    "\n",
    "`scrapy startproject <project_name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T15:42:56.442184Z",
     "start_time": "2020-04-23T15:42:55.611319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'tutorial', using template directory 'C:\\Users\\User\\anaconda3\\envs\\web_venv\\lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    C:\\Users\\User\\Desktop\\web_scrapping\\0. Notebooks\\tutorial\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd tutorial\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "! scrapy startproject tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행하면 __tutorial__ 디렉토리가 생성되고 아래와 같은 구조로 구성되어 있다.\n",
    "\n",
    "```\n",
    "tutorial/\n",
    "    scrapy.cfg            # deploy 설정 파일\n",
    "    tutorial/             # 프로젝트의 파이썬 모듈, 여기서 코드를 import 한다\n",
    "        __init__.py\n",
    "        items.py          # items 정의\n",
    "        middlewares.py    # middlewares 파일\n",
    "        pipelines.py      # pipelines 파일\n",
    "        settings.py       # 설정 파일\n",
    "        spiders/          # 나중에 나만의 spiders를 넣을 디렉토리\n",
    "            __init__.py|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T02:25:20.968656Z",
     "start_time": "2020-04-24T02:25:20.936761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 PATH의 목록입니다.\n",
      "볼륨 일련 번호는 3ADA-D4B8입니다.\n",
      "C:\\USERS\\USER\\DESKTOP\\WEB_SCRAPPING\\0. NOTEBOOKS\\TUTORIAL\n",
      "│  scrapy.cfg\n",
      "│  \n",
      "└─tutorial\n",
      "    │  items.py\n",
      "    │  middlewares.py\n",
      "    │  pipelines.py\n",
      "    │  settings.py\n",
      "    │  __init__.py\n",
      "    │  \n",
      "    ├─spiders\n",
      "    │  │  __init__.py\n",
      "    │  │  \n",
      "    │  └─__pycache__\n",
      "    └─__pycache__\n"
     ]
    }
   ],
   "source": [
    "! tree /F tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Our first Spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Spiders__ 는 웹사이트에서 정보를 스크랩할 때 Scrapy가 사용하는 사용자 정의 클래스들이다. `Spider` 클래스를 상속받아 최초 요청, 선택적으로 페이지의 링크를 따르는 방법, 다운로드한 페이지 내용을 구문 분석하여 데이터를 추출하는 방법 등을 정의해야 한다.\n",
    "\n",
    "`tutorial/spiders` 디렉토리 아래에 새로운 파일 `quotes_spider.py`를 생성하고 아래의 코드를 입력하여 나의 첫 Spider를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T02:36:44.019777Z",
     "start_time": "2020-04-24T02:36:44.014803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tutorial/tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tutorial/tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'http://quotes.toscrape.com/page/1/',\n",
    "            'http://quotes.toscrape.com/page/2/',\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "            \n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f'quotes-{page}.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        self.log(f'Saved file {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__scrapy.Spider__ 를 상속받고 속성과 메소드들 몇 개를 추가하였다.\n",
    "\n",
    "- `name` : \n",
    "    - Spider를 구분하기 때문에 프로젝트에서 unique한 값을 가져야 한다.\n",
    "\n",
    "- `start_requests()` : \n",
    "    - Requests 반복자를 반환해야한다. (list로 반환해도 되고 위 코드처럼 generator 함수를 반환해도 된다)\n",
    "\n",
    "- `parse()` : \n",
    "    - 각 요청(request)에 대해 다운로드되는 응답(response)을 처리하는 메소드를 호출\n",
    "    - response 인자는 페이지 내용을 보관하는 TextResponse의 한 인스턴스\n",
    "    - 주로 response를 구문 분석하고, dicts 타입으로 스크랩된 데이터를 추출하고 새로운 URLs를 찾아 new requests 폼을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### How to run our spider\n",
    "\n",
    "__프로젝트 가장 상위 디렉토리__ 로 이동하여 아래 명령어를 실행한다.\n",
    "\n",
    "`scrapy crawl <spider_name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T03:39:13.725702Z",
     "start_time": "2020-04-24T03:39:10.484086Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\web_scrapping\\0. Notebooks\\tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-24 12:39:11 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: tutorial)\n",
      "2020-04-24 12:39:11 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.8.2 (default, Apr 14 2020, 19:01:40) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0\n",
      "2020-04-24 12:39:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}\n",
      "2020-04-24 12:39:11 [scrapy.extensions.telnet] INFO: Telnet Password: 83c7df4d484c55d6\n",
      "2020-04-24 12:39:11 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-04-24 12:39:11 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-04-24 12:39:11 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-04-24 12:39:11 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-04-24 12:39:11 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-04-24 12:39:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-04-24 12:39:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-04-24 12:39:12 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
      "2020-04-24 12:39:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2020-04-24 12:39:13 [quotes] DEBUG: Saved file quotes-1.html\n",
      "2020-04-24 12:39:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
      "2020-04-24 12:39:13 [quotes] DEBUG: Saved file quotes-2.html\n",
      "2020-04-24 12:39:13 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-04-24 12:39:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 678,\n",
      " 'downloader/request_count': 3,\n",
      " 'downloader/request_method_count/GET': 3,\n",
      " 'downloader/response_bytes': 6003,\n",
      " 'downloader/response_count': 3,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/404': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 4, 24, 3, 39, 13, 655926),\n",
      " 'log_count/DEBUG': 5,\n",
      " 'log_count/INFO': 9,\n",
      " 'response_received_count': 3,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/404': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2020, 4, 24, 3, 39, 11, 491721)}\n",
      "2020-04-24 12:39:13 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "% cd tutorial\n",
    "! scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 생성한 `quotes` spider를 통해 [quotes.toscrape.com](http://quotes.toscrape.com/) 도메인에 requests를 보냈다. 결과는 아래와 비슷하게 출력되는 것을 볼 수 있다.\n",
    "\n",
    "``` java\n",
    "... (생략)\n",
    "2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened\n",
    "2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
    "2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n",
    "2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
    "2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
    "2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
    "2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html\n",
    "2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html\n",
    "2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
    "```\n",
    "\n",
    "현재 디렉토리(`/tutorial`)를 살펴보면 두 개의 새로운 파일 \"quotes-1.html\", \"quotes-2.html\" 이 생성된 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What just happend under the hood?\n",
    "\n",
    "Scrapy가 스케줄을 짠다. Spider의 `start_requests()` 메서드로 반환된 객체 요청(`scrapy.Request`) 각각에 대한 응답(`Response`)을 받으면, 응답 객체를 인스턴스화하고, 요청과 관련된 콜백 방법(이 경우, `parse` 방법)을 인수로 전달하여 호출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A shortcut to the start_requests method\n",
    "\n",
    "`start_requests()` 메소드를 구현하는 것 말고 그냥 `start_urls` 클래스 속성을 정의할 수 있다. 그러면 spider에 기본으로 구현된 `start_requests()` 메소드에 사용되어 initial 요청을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T04:02:23.817074Z",
     "start_time": "2020-04-24T04:02:23.812085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tutorial/spiders/quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "        'http://quotes.toscrape.com/page/2/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = 'quotes-%s.html' % page\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특별한 명시가 없었는데도 `parse()` 메소드가 리스트에 있는 URLs의 요청을 처리하는 것을 볼 수 있다. 이는 Scrapy의 기본 callback 메소드가 `parse()`이기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Extracting data\n",
    "\n",
    "Scrapy를 사용한 데이터 추출을 배우는 가장 좋은 방법은 [Scrapy shell](https://doc.scrapy.org/en/2.0/topics/shell.html#topics-shell)을 사용하는 것이다.\n",
    "\n",
    "> shell이란? 스파이더를 실행하지 않고도 스크래핑 코드를 빠르게 시도하고 디버깅 할 수 있다. 데이터 추출 코드를 테스트 하는 데 사용하지만, 일반 python 셸이므로 모든 종류의 코드를 테스트 가능하다.\n",
    "\n",
    "shell 환경에서는 `scrapy shell <URL>` 명령어로 간단하게 실행 가능하다.\n",
    "\n",
    "ex) `scrapy shell \"http://quotes.toscrape.com/page/1/\"`\n",
    "\n",
    "\n",
    "여기 노트북에서는 아래와 같은 방법으로 실행한다.\n",
    "\n",
    "참고) [stackoverflow](https://stackoverflow.com/questions/49908158/using-scrapy-in-jupyter-notebook-accessing-response-directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:49:15.313010Z",
     "start_time": "2020-04-28T13:49:13.585786Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "\n",
    "\n",
    "res = requests.get(\"http://quotes.toscrape.com/page/1/\")\n",
    "response = TextResponse(res.url, body=res.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CSS__ 를 사용하여 response 객체의 특정 elements를 선택할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T04:22:35.161935Z",
     "start_time": "2020-04-24T04:22:35.151936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='descendant-or-self::title' data='<title>Quotes to Scrape</title>'>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SelectorList` 라는 list-like 객체를 반환한다.\n",
    "\n",
    "XML/HTML 요소들로 감싸진 `Selector` 객체들의 리스트를 나타낸다.\n",
    "\n",
    "나아가 query를 통해 선택 항목을 미세하게 그라인(fine-grine)하거나 데이터를 추출할 수 있다.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "__title에서 텍스트를 추출__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:49:16.202666Z",
     "start_time": "2020-04-28T13:49:16.182375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quotes to Scrape']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title::text').getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 주목해야 할 두 가지가 있는데, \n",
    "\n",
    "- 첫째는 CSS 쿼리에 `::text`, 즉 `<title>` 요소 바로 안에 있는 텍스트 요소만을 선택하고자 함을 의미한다. \n",
    "\n",
    "    `::text`를 지정하지 않으면 태그를 포함한 전체 제목 요소를 얻게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:52:14.332042Z",
     "start_time": "2020-04-28T13:52:14.326059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<title>Quotes to Scrape</title>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title').getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다른 하나는 `.getall()`을 호출한 결과가 list라는 것이다. \n",
    "\n",
    "    첫 번째 결과만 얻고 싶다면 `get()`을 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:52:34.772451Z",
     "start_time": "2020-04-28T13:52:34.742947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quotes to Scrape'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title::text').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re()` 메소드를 사용한 정규표현식으로도 데이터를 추출할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:59:41.532898Z",
     "start_time": "2020-04-28T13:59:41.512804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quotes to Scrape']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title::text').re(r'Quotes.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:59:34.232947Z",
     "start_time": "2020-04-28T13:59:34.212659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quotes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title::text').re(r'Q\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:59:39.732547Z",
     "start_time": "2020-04-28T13:59:39.716423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quotes', 'Scrape']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css('title::text').re(r'(\\w+) to (\\w+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### XPath: a brief intro\n",
    "\n",
    "[CSS](https://www.w3.org/TR/selectors/) 이외에도 Scrapy의 selector는 [XPath](https://www.w3.org/TR/xpath/all/) 표현식을 지원한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:03:16.888054Z",
     "start_time": "2020-04-28T14:03:16.883067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.xpath('//title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:03:13.013088Z",
     "start_time": "2020-04-28T14:03:13.002780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quotes to Scrape'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.xpath('//title/text()').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__XPath expression__ 은 매우 강력하며 Scrapy Selectors의 기초가 된다. \n",
    "\n",
    "실제로는 CSS selector들이 최신형 XPath로 변환되는 것이다.\n",
    "\n",
    "\n",
    "XPath 표현은 CSS selector들 만큼 인기있지 않지만, 구조를 탐색하는 것 외에도 내용을 볼 수 있기 때문에 유용하다. XPath를 사용하면 다음과 같은 것을 할 수 있다 :\n",
    "\n",
    "`select the link that contains the text \"Next Page\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting quotes and authors\n",
    "\n",
    "이제 웹페이지에서 인용문을 추출할 코드를 작성해서 spider을 완성하자.\n",
    "\n",
    "[http://quotes.toscrape.com](http://quotes.toscrape.com) 의 각 인용문은 다음과 같은 HTML 형식으로 표현된다.\n",
    "\n",
    "``` HTML\n",
    "\n",
    "<div class=\"quote\">\n",
    "    <span class=\"text\">“The world as we have created it is a process of our\n",
    "    thinking. It cannot be changed without changing our thinking.”</span>\n",
    "    <span>\n",
    "        by <small class=\"author\">Albert Einstein</small>\n",
    "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
    "    </span>\n",
    "    <div class=\"tags\">\n",
    "        Tags:\n",
    "        <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
    "        <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
    "        <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
    "        <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "__scrapy shell을 사용하여 어떻게 데이터를 추출할지 연습해보자.__\n",
    "\n",
    "> class가 \"quote\"인 div 태그를 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:17:02.420370Z",
     "start_time": "2020-04-28T14:17:01.710875Z"
    }
   },
   "outputs": [],
   "source": [
    "res = requests.get(\"http://quotes.toscrape.com\")\n",
    "response = TextResponse(res.url, body=res.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:22:42.873163Z",
     "start_time": "2020-04-28T14:22:42.843585Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>,\n",
       " <Selector xpath=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ')]\" data='<div class=\"quote\" itemscope itemtype...'>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.css(\"div.quote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "응답받는 많은 인용문 중에서 첫번째 인용문을 변수에 저장하고, 여기서 `text`, `author`, `tags` 를 각각 추출해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:27:40.893646Z",
     "start_time": "2020-04-28T14:27:40.873564Z"
    }
   },
   "outputs": [],
   "source": [
    "quote = response.css(\"div.quote\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:27:49.873246Z",
     "start_time": "2020-04-28T14:27:49.853152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = quote.css(\"span.text::text\").get()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:28:39.813211Z",
     "start_time": "2020-04-28T14:28:39.803283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = quote.css(\"small.author::text\").get()\n",
    "author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러개의 태그가 있기 때문에 `getall()` 메소드를 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:29:49.993601Z",
     "start_time": "2020-04-28T14:29:49.973326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change', 'deep-thoughts', 'thinking', 'world']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 더 깔끔하게 파이썬 딕셔너리로 저장하여 출력해보자.\n",
    "\n",
    "> 깔끔하게 보이기 위해 `pprint` 패키지 사용했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:35:26.693449Z",
     "start_time": "2020-04-28T14:35:26.673865Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Albert Einstein',\n",
      " 'tags': ['change', 'deep-thoughts', 'thinking', 'world'],\n",
      " 'text': '“The world as we have created it is a process of our thinking. It '\n",
      "         'cannot be changed without changing our thinking.”'}\n",
      "{'author': 'J.K. Rowling',\n",
      " 'tags': ['abilities', 'choices'],\n",
      " 'text': '“It is our choices, Harry, that show what we truly are, far more '\n",
      "         'than our abilities.”'}\n",
      "{'author': 'Albert Einstein',\n",
      " 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles'],\n",
      " 'text': '“There are only two ways to live your life. One is as though nothing '\n",
      "         'is a miracle. The other is as though everything is a miracle.”'}\n",
      "{'author': 'Jane Austen',\n",
      " 'tags': ['aliteracy', 'books', 'classic', 'humor'],\n",
      " 'text': '“The person, be it gentleman or lady, who has not pleasure in a good '\n",
      "         'novel, must be intolerably stupid.”'}\n",
      "{'author': 'Marilyn Monroe',\n",
      " 'tags': ['be-yourself', 'inspirational'],\n",
      " 'text': \"“Imperfection is beauty, madness is genius and it's better to be \"\n",
      "         'absolutely ridiculous than absolutely boring.”'}\n",
      "{'author': 'Albert Einstein',\n",
      " 'tags': ['adulthood', 'success', 'value'],\n",
      " 'text': '“Try not to become a man of success. Rather become a man of value.”'}\n",
      "{'author': 'André Gide',\n",
      " 'tags': ['life', 'love'],\n",
      " 'text': '“It is better to be hated for what you are than to be loved for what '\n",
      "         'you are not.”'}\n",
      "{'author': 'Thomas A. Edison',\n",
      " 'tags': ['edison', 'failure', 'inspirational', 'paraphrased'],\n",
      " 'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\"}\n",
      "{'author': 'Eleanor Roosevelt',\n",
      " 'tags': ['misattributed-eleanor-roosevelt'],\n",
      " 'text': '“A woman is like a tea bag; you never know how strong it is until '\n",
      "         \"it's in hot water.”\"}\n",
      "{'author': 'Steve Martin',\n",
      " 'tags': ['humor', 'obvious', 'simile'],\n",
      " 'text': '“A day without sunshine is like, you know, night.”'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for quote in response.css(\"div.quote\"):\n",
    "    text = quote.css(\"span.text::text\").get()\n",
    "    author = quote.css(\"small.author::text\").get()\n",
    "    tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "    \n",
    "    pprint(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Extracting data in our spider\n",
    "\n",
    "이제 다시 spider 로 돌아가보자.\n",
    "\n",
    "현재 spider의 기능은 전체 HTML 페이지를 local 파일로 저장하는 것 뿐이다.\n",
    "\n",
    "위에서 했던 과정을 spider에 적용시키자.\n",
    "\n",
    "<br>\n",
    "\n",
    "Scrapy의 spider는 많은 딕셔너리들을 생성하기 때문에 `yield` 키워드를 사용해 callback하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:43:01.673893Z",
     "start_time": "2020-04-28T14:43:01.643957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tutorial/spiders/quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tutorial/spiders/quotes_spider.py\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "        'http://quotes.toscrape.com/page/2/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일을 수정하고 spider를 실행하면 아래와 같은 결과를 볼 수 있다.\n",
    "\n",
    "```\n",
    "2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
    "{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}\n",
    "2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
    "{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:43:20.213483Z",
     "start_time": "2020-04-28T14:43:15.363711Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 23:43:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: tutorial)\n",
      "2020-04-28 23:43:16 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.8.2 (default, Apr 14 2020, 19:01:40) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0\n",
      "2020-04-28 23:43:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}\n",
      "2020-04-28 23:43:16 [scrapy.extensions.telnet] INFO: Telnet Password: cc4e1872132f57e8\n",
      "2020-04-28 23:43:16 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-04-28 23:43:16 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-04-28 23:43:16 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-04-28 23:43:16 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-04-28 23:43:16 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-04-28 23:43:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-04-28 23:43:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-04-28 23:43:17 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
      "2020-04-28 23:43:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", 'author': 'Marilyn Monroe', 'tags': ['friends', 'heartbreak', 'inspirational', 'life', 'love', 'sisters']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', 'author': 'J.K. Rowling', 'tags': ['courage', 'friends']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“If you can't explain it to a six year old, you don't understand it yourself.”\", 'author': 'Albert Einstein', 'tags': ['simplicity', 'understand']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect\\u2014you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break\\u2014her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", 'author': 'Bob Marley', 'tags': ['love']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', 'author': 'Dr. Seuss', 'tags': ['fantasy']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', 'author': 'Douglas Adams', 'tags': ['life', 'navigation']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", 'author': 'Elie Wiesel', 'tags': ['activism', 'apathy', 'hate', 'indifference', 'inspirational', 'love', 'opposite', 'philosophy']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', 'author': 'Friedrich Nietzsche', 'tags': ['friendship', 'lack-of-friendship', 'lack-of-love', 'love', 'marriage', 'unhappy-marriage']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', 'author': 'Mark Twain', 'tags': ['books', 'contentment', 'friends', 'friendship', 'life']}\n",
      "2020-04-28 23:43:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“Life is what happens to us while we are making other plans.”', 'author': 'Allen Saunders', 'tags': ['fate', 'life', 'misattributed-john-lennon', 'planning', 'plans']}\n",
      "2020-04-28 23:43:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'Andr\\xe9 Gide', 'tags': ['life', 'love']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
      "2020-04-28 23:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n",
      "2020-04-28 23:43:20 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-04-28 23:43:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 678,\n",
      " 'downloader/request_count': 3,\n",
      " 'downloader/request_method_count/GET': 3,\n",
      " 'downloader/response_bytes': 6003,\n",
      " 'downloader/response_count': 3,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/404': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 4, 28, 14, 43, 20, 113921),\n",
      " 'item_scraped_count': 20,\n",
      " 'log_count/DEBUG': 23,\n",
      " 'log_count/INFO': 9,\n",
      " 'response_received_count': 3,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/404': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2020, 4, 28, 14, 43, 16, 523738)}\n",
      "2020-04-28 23:43:20 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Storing the scraped data\n",
    "\n",
    "스크랩한 데이터를 저장하는 가장 간단한 방법은 [Feed exports](https://doc.scrapy.org/en/2.0/topics/feed-exports.html#topics-feed-exports) (JSON, CSV 등)를 사용하는 것이다.\n",
    "\n",
    "아래 명령어를 통해 JSON 파일을 생성하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T14:49:56.063568Z",
     "start_time": "2020-04-28T14:49:53.323544Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 23:49:54 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: tutorial)\n",
      "2020-04-28 23:49:54 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.8.2 (default, Apr 14 2020, 19:01:40) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0\n",
      "2020-04-28 23:49:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'FEED_FORMAT': 'json', 'FEED_URI': 'quotes.json', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}\n",
      "2020-04-28 23:49:54 [scrapy.extensions.telnet] INFO: Telnet Password: 03df4fb460b8477f\n",
      "2020-04-28 23:49:54 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-04-28 23:49:54 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-04-28 23:49:54 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-04-28 23:49:54 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-04-28 23:49:54 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-04-28 23:49:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-04-28 23:49:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-04-28 23:49:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
      "2020-04-28 23:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'Andr\\xe9 Gide', 'tags': ['life', 'love']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "\n",
      "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n",
      "2020-04-28 23:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", 'author': 'Marilyn Monroe', 'tags': ['friends', 'heartbreak', 'inspirational', 'life', 'love', 'sisters']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', 'author': 'J.K. Rowling', 'tags': ['courage', 'friends']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“If you can't explain it to a six year old, you don't understand it yourself.”\", 'author': 'Albert Einstein', 'tags': ['simplicity', 'understand']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect\\u2014you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break\\u2014her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", 'author': 'Bob Marley', 'tags': ['love']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', 'author': 'Dr. Seuss', 'tags': ['fantasy']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', 'author': 'Douglas Adams', 'tags': ['life', 'navigation']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", 'author': 'Elie Wiesel', 'tags': ['activism', 'apathy', 'hate', 'indifference', 'inspirational', 'love', 'opposite', 'philosophy']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', 'author': 'Friedrich Nietzsche', 'tags': ['friendship', 'lack-of-friendship', 'lack-of-love', 'love', 'marriage', 'unhappy-marriage']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', 'author': 'Mark Twain', 'tags': ['books', 'contentment', 'friends', 'friendship', 'life']}\n",
      "2020-04-28 23:49:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "\n",
      "{'text': '“Life is what happens to us while we are making other plans.”', 'author': 'Allen Saunders', 'tags': ['fate', 'life', 'misattributed-john-lennon', 'planning', 'plans']}\n",
      "2020-04-28 23:49:55 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-04-28 23:49:55 [scrapy.extensions.feedexport] INFO: Stored json feed (20 items) in: quotes.json\n",
      "2020-04-28 23:49:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 678,\n",
      " 'downloader/request_count': 3,\n",
      " 'downloader/request_method_count/GET': 3,\n",
      " 'downloader/response_bytes': 6003,\n",
      " 'downloader/response_count': 3,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/404': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 4, 28, 14, 49, 55, 963832),\n",
      " 'item_scraped_count': 20,\n",
      " 'log_count/DEBUG': 23,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 3,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/404': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2020, 4, 28, 14, 49, 54, 303882)}\n",
      "2020-04-28 23:49:55 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! scrapy crawl quotes -o quotes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역사적인(historic) 이유로(?) 같은 명령을 두 번 실행하면 Scrapy는 파일을 덮어씌우는게 아니라 뒤에 덧붙인다.\n",
    "\n",
    "즉 명령어를 다시 실행하기 전에 이전 파일을 지워야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
